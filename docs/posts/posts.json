[
  {
    "path": "posts/2022-02-23-flattening-lists/",
    "title": "Flattening lists",
    "description": "In this post, I explore various ways of flattening hierarchical lists in \nPython, contrasting with the built-in `unlist` function in R",
    "author": [
      {
        "name": "Abhijit Dasgupta",
        "url": {}
      }
    ],
    "date": "2022-02-23",
    "categories": [
      "r",
      "python",
      "data munging"
    ],
    "contents": "\n\nContents\nIntroducing the problem\nFirst attempt\nDoing this in Python\nFinding a resource\nThe common method\nFunctional programming and reduce\nUsing pandas\nUsing itertools\n\n\nIntroducing the problem\nToday, we will focus on the results of splitting text fields by a delimiter in R and Python. This will typically result in a list of lists. However, that would not do for my purpose.\nThe situation I was facing was to parse a text field containing one or more comma-separated disease names that were afflicting each patient in a study, and I wanted to make a frequency distribution of all the diseases among patients in the study, knowing that each disease would only appear at most once per patient. So I had to flatten the list of lists I would get by parsing the text field, so that I could then send it to a tabulation function like table in R or numpy.unique(..., return_counts=True) in Python.\nFirst attempt\nLet’s start with a text array containing the data in question.This data is an excerpt from a dataset provided for the PKDD ’99 Discovery Challenge\n\n\ndat = readr::read_csv('dat.csv')\nhead(dat)\n\n\n# A tibble: 6 × 1\n  Diagnosis   \n  <chr>       \n1 RA susp.    \n2 PSS         \n3 SLE         \n4 MCTD        \n5 RA, SLE susp\n6 SLE, MCTD   \n\nThere are comma-separated diseases here. We’ll ignore the obvious need to clean the text field of extraneous spaces for now. Let’s try separating out the different diseases.\n\n\nstringr::str_split(dat$Diagnosis, \",\")[1:5]\n\n\n[[1]]\n[1] \"RA susp.\"\n\n[[2]]\n[1] \"PSS\"\n\n[[3]]\n[1] \"SLE\"\n\n[[4]]\n[1] \"MCTD\"\n\n[[5]]\n[1] \"RA\"        \" SLE susp\"\n\nWe see that this is a list of vectors (so we can nominally consider it a list of lists), some of length 1 and some with length more than 1. In order to tabulate the data, all we need is the unlist function.\n\n\ntable(unlist(stringr::str_split(dat$Diagnosis, \",\")))\n\n\n\n                     AIHA                  AORTITIS \n                        1                         1 \n                     MCTD                        RA \n                        2                         1 \n                  RA susp                       SJS \n                        1                        11 \n                 SLE susp                   TA susp \n                        1                         1 \n                 AORTITIS                    BEHCET \n                        1                         7 \n          BEHCET (òsæSî^)          BEHCET (vasculo) \n                        1                         1 \n              BEHCET susp                 Hyper CPK \n                        1                         1 \n                     MCTD                       MRA \n                        5                         1 \n                       PM                     PM/DM \n                        3                         3 \n          PN (vasculitis)                       PSS \n                        1                         6 \n                 PSS susp                PSS(CREST) \n                        1                         1 \n                       RA                   RA susp \n                       12                         2 \n                 RA susp.      Raynaud's phenomenon \n                        1                         1 \nrelapsingü@polychondritis           seronegative RA \n                        1                         1 \n                      SJS                  SJS susp \n                       13                         4 \n                      SLE                     Sweet \n                       30                         1 \n    urticarial vasculitis                vasculitis \n                        1                         1 \n\nVoila!!!\nDoing this in Python\nIt turns out, doing a similar operation would also get you a list of lists in Python\n\nimport pandas as pd\ndat = pd.read_csv('dat.csv')\nd = dat.Diagnosis.str.split(\",\")\nd[:5]\n0         [RA susp.]\n1              [PSS]\n2              [SLE]\n3             [MCTD]\n4    [RA,  SLE susp]\nName: Diagnosis, dtype: object\n\nIt turns out, we don’t have an unlist function in Python!!\nFinding a resource\nGoogle being the all-encompassing deity of knowledge, I turned there and found this post describing 25 ways to flatten a list (and obviously a Simon and Garfunkel fan). There are a couple of one-liners in that post that I’ll highlight here.\nThe common method\nSearches for this problem most commonly provide the following solution, either as a for-loop or a list comprehension\n\nflatten_list = []\nfor sublist in d:\n    for item in sublist:\n        flatten_list.append(item)\nflatten_list[:8]\n['RA susp.', 'PSS', 'SLE', 'MCTD', 'RA', ' SLE susp', 'SLE', ' MCTD']\n\nFunctional programming and reduce\n\nfrom functools import reduce\nreduce(list.__add__, d)[:8]\n['RA susp.', 'PSS', 'SLE', 'MCTD', 'RA', ' SLE susp', 'SLE', ' MCTD']\n\nFunctional programming provides functions that act on functions. Here, the reduce function applies the list.__add__ function recursively to successive elements of d, noting that adding two lists serves to concatenate them in Python.\nA variant on this theme that works is\n\nsum(d, [])[:8]\n['RA susp.', 'PSS', 'SLE', 'MCTD', 'RA', ' SLE susp', 'SLE', ' MCTD']\n\nsince the sum function applies addition recursively from a starting value, which is the second argument. Here the addition operation is overloaded for lists to concatenate lists.\nUsing pandas\npandas does have a flatten function hidden in its depths\n\nfrom pandas.core.common import flatten\nlist(flatten(d))[:8]\n['RA susp.', 'PSS', 'SLE', 'MCTD', 'RA', ' SLE susp', 'SLE', ' MCTD']\n\nUsing itertools\n\nimport itertools\nlist(itertools.chain(*d))[:8]\n['RA susp.', 'PSS', 'SLE', 'MCTD', 'RA', ' SLE susp', 'SLE', ' MCTD']\n\n\n\n\n",
    "preview": {},
    "last_modified": "2022-02-23T07:15:52-05:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-02-21-frequency-counts-from-lists/",
    "title": "Frequency counts from lists",
    "description": "In this post I look at better ways of obtaining frequency distributions from a Python list, using methods **other than pandas**",
    "author": [
      {
        "name": "Abhijit Dasgupta",
        "url": {}
      }
    ],
    "date": "2022-02-21",
    "categories": [
      "python",
      "statistics"
    ],
    "contents": "\n\nContents\nIntroducing the problem\nBetter ways\nUsing collections\nUsing numpy\nTimings\n\n\nIntroducing the problem\nHow to you compute a frequency table from a list in Python? We’ll use a list named dat which is created by sampling the first 5 letters.\n\nimport string\nimport random\n\ndat = random.choices(string.ascii_lowercase[:5], k = 100)\n\nOne way, that I use all the time, is\n\nimport pandas as pd\npd.Series(dat).value_counts()\nb    26\ne    22\nc    20\na    18\nd    14\ndtype: int64\n\nBut can you do this without pandas? Turns out, you can\nBetter ways\nUsing collections\n\nimport collections\npd.Series(collections.Counter(dat))\nd    14\nb    26\nc    20\na    18\ne    22\ndtype: int64\n\nThis creates a Series out of the output of Counter, which is a dict-like object.\nUsing numpy\n\nimport numpy as np\nans = np.unique(dat, return_counts=True)\n\nThis returns a tuple, which can be converted several ways, per this StackOverflow answer\n\npd.DataFrame(np.column_stack(ans), columns = ['item','count'])\n  item count\n0    a    18\n1    b    26\n2    c    20\n3    d    14\n4    e    22\npd.DataFrame(np.vstack(ans).T, columns = ['item','count'])\n  item count\n0    a    18\n1    b    26\n2    c    20\n3    d    14\n4    e    22\npd.DataFrame(np.transpose(ans), columns = ['item','count'])\n  item count\n0    a    18\n1    b    26\n2    c    20\n3    d    14\n4    e    22\n\nTimings\nLet’s look at timings for each of these methods.\n\nimport timeit\nmysetup = \"\"\"\nimport pandas as pd\nimport numpy as np\nimport collections, random, string\ndat = random.choices(string.ascii_lowercase[:5], k=1000)\ndat1 = pd.Series(dat)\n\"\"\"\n\n\ntimeit.timeit('pd.Series(dat).value_counts()', setup=mysetup, number=1000)/1000\n0.00046380726499955924\ntimeit.timeit('pd.Series(collections.Counter(dat))', setup=mysetup, number=1000)/1000\n0.000220889652000551\ntimeit.timeit('pd.DataFrame(np.column_stack(np.unique(dat, return_counts=True)))', setup=mysetup, number=1000)/1000\n0.00025998155500019495\ntimeit.timeit('pd.DataFrame(np.vstack(np.unique(dat, return_counts=True)).T)', setup=mysetup, number=1000)/1000\n0.0002631664059990726\ntimeit.timeit('pd.DataFrame(np.transpose(np.unique(dat, return_counts=True)))', setup=mysetup, number=1000)/1000\n0.0002664510020003945\n\nSo we can see that my usual strategy is half as efficient as the other strategies described in this post !!\nWhat about if we start with a pandas Series anyway, and forgo the casting into a pandas structure?\n\ntimeit.timeit(\"dat1.value_counts()\", setup=mysetup, number=1000)/1000\n0.0003267870910003694\ntimeit.timeit(\"collections.Counter(dat1)\", setup=mysetup, number=1000)/1000\n9.801131499989425e-05\n\nEven here, the pandas method is at quite the disadvantage.\n\n\n\n",
    "preview": {},
    "last_modified": "2022-02-22T03:02:31-05:00",
    "input_file": {}
  }
]

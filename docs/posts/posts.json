[
  {
    "path": "posts/2022-02-21-frequency-counts-from-lists/",
    "title": "Frequency counts from lists",
    "description": "In this post I look at better ways of obtaining frequency distributions from a Python list, using methods **other than pandas**",
    "author": [
      {
        "name": "Abhijit Dasgupta",
        "url": {}
      }
    ],
    "date": "2022-02-21",
    "categories": [
      "Python"
    ],
    "contents": "\nHow to you compute a frequency table from a list in Python? We’ll use a list named dat which is created by sampling the first 5 letters.\n\nimport string\nimport random\n\ndat = random.choices(string.ascii_lowercase[:5], k = 100)\n\nOne way, that I use all the time, is\n\nimport pandas as pd\npd.Series(dat).value_counts()\nb    22\nd    22\ne    22\nc    21\na    13\ndtype: int64\n\nBut can you do this without pandas? Turns out, you can\nUsing collections\n\nimport collections\npd.Series(collections.Counter(dat))\nb    22\nc    21\nd    22\ne    22\na    13\ndtype: int64\n\nThis creates a Series out of the output of Counter, which is a dict-like object.\nUsing numpy\n\nimport numpy as np\nans = np.unique(dat, return_counts=True)\n\nThis returns a tuple, which can be converted several ways, per this StackOverflow answer\n\npd.DataFrame(np.column_stack(ans), columns = ['item','count'])\n  item count\n0    a    13\n1    b    22\n2    c    21\n3    d    22\n4    e    22\npd.DataFrame(np.vstack(ans).T, columns = ['item','count'])\n  item count\n0    a    13\n1    b    22\n2    c    21\n3    d    22\n4    e    22\npd.DataFrame(np.transpose(ans), columns = ['item','count'])\n  item count\n0    a    13\n1    b    22\n2    c    21\n3    d    22\n4    e    22\n\nTimings\nLet’s look at timings for each of these methods.\n\nimport timeit\nmysetup = \"\"\"\nimport pandas as pd\nimport numpy as np\nimport collections, random, string\ndat = random.choices(string.ascii_lowercase[:5], k=1000)\n\"\"\"\n\n\ntimeit.timeit('pd.Series(dat).value_counts()', setup=mysetup, number=1000)/1000\n0.0005386214850000002\ntimeit.timeit('pd.Series(collections.Counter(dat))', setup=mysetup, number=1000)/1000\n0.00024093244599999997\ntimeit.timeit('pd.DataFrame(np.column_stack(np.unique(dat, return_counts=True)))', setup=mysetup, number=1000)/1000\n0.0002909272760000001\ntimeit.timeit('pd.DataFrame(np.vstack(np.unique(dat, return_counts=True)).T)', setup=mysetup, number=1000)/1000\n0.0002756786\ntimeit.timeit('pd.DataFrame(np.transpose(np.unique(dat, return_counts=True)))', setup=mysetup, number=1000)/1000\n0.00027493610299999995\n\nSo we can see that my usual strategy is half as efficient as the other strategies described in this post !!\n\n\n\n",
    "preview": {},
    "last_modified": "2022-02-22T00:37:32-05:00",
    "input_file": {}
  }
]
